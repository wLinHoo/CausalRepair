# CausalRepair: Bridging the Causality Gap in LLM-based APR via Dual-Slicing

CausalRepair is a novel Automated Program Repair (APR) framework designed to bridge the "causality gap" in Large Language Model (LLM)-based repair. By leveraging a synergistic dual-slicing strategy, the framework constructs a Minimal Causal Context that eliminates noise from unexecuted code and resolves test context ambiguity.

This repo contains both the correct patches generated by our study along with the code used to run the experiment.

## Overview

- Constructing Minimal Causal Context: Employs context-aware static slicing on the test side and execution-trace-based dynamic slicing (via Slicer4J) on the source side to isolate bug-related dependencies.

- Conversation-driven Iterative Repair: Utilizes a "generate-validate-feedback" loop where LLMs refine patches based on real-time execution diagnostics.

- Patch Augmentation: Generates diverse variations of plausible patches to mitigate test suite overfitting and increase the likelihood of semantic correctness.

## Environment Setup

### 1. Prerequisites

- JDK 1.8: Required for Defects4J.

```
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH
```

- Defects4J: Ensure Defects4J is installed and the framework binaries are added to your PATH.

```
Install Defects4J from https://github.com/rjust/defects4j 
export PATH=$PATH:"path2defects4j"/framework/bin
```

- Python 3.8+: Recommended for running the repair scripts.


### 2. API Configuration
Configure your API keys in `utils/api_request.py`. The framework supports SiliconFlow, OpenAI, and Zhipu AI.


## Project Structure

```
CausalRepair
├── Results/                    # Final correct patches generated by our study
├── Defects4j/                  # Metadata
├── utils/
│   ├── api_request.py          # LLM API request handling
│   ├── parse_d4j.py            # D4J data parsing
│   ├── prompt.py               # Prompt templates
│   └── validate_d4j.py         # Validation logic
├── iterative_repair.py         # Core iterative repair script
├── collect_plausible_patches.py # Script to extract valid candidates
└── augment_patches.py          # Patch augmentation script
```

## Plausible patches generation

### Step 1: Iterative Repair

Run the initial repair process using `iterative_repair.py`. This script constructs the causal context and engages in multi-round debugging with the LLM.

Example Command:
```
python iterative_repair.py \
     --provider siliconflow \
     --model "deepseek-ai/DeepSeek-V3" \
     --folder ./results/result_d4j1.2 \
     --d4j_version 1.2 \
     --max_rounds 5 \
     --max_attempts_per_round 3 \
     --use_slice
```

### Step 2: Collecting Plausible Patches

After the iterative repair, extract patches that pass all test cases by running `collect_plausible_patches.py`. Ensure the input_file path in the script matches your output folder from Step 1.

```
python collect_plausible_patches.py
```

Step 3: Patch Augmentation (Phase 3)

Use `augment_patches.py` to explore the solution space surrounding the plausible patches to find the correct fix.

Example Command:
```
python augment_patches.py \
     --input_plausible ./plausible_patches.json \
     --output_folder ./augmentation_output \
     --max_attempts 10
```

## Experimental Results

All patches successfully repaired by CausalRepair, which are semantically equivalent to developer-provided fixes, are located in the Results/ directory.
